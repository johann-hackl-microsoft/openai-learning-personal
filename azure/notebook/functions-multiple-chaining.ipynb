{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure functions example\n",
    "\n",
    "This notebook shows how to use the function calling capability with the Azure OpenAI service. Functions allow a caller of chat completions to define capabilities that the model can use to extend its\n",
    "functionality into external tools and data sources.\n",
    "\n",
    "You can read more about chat functions on OpenAI's blog: https://openai.com/blog/function-calling-and-other-api-updates\n",
    "\n",
    "**NOTE**: Chat functions require model versions beginning with gpt-4 and gpt-35-turbo's `-0613` labels. They are not supported by older versions of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we install the necessary dependencies and import the libraries we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai<2.0.0,>=1.0.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (1.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.0.0) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.0.0) (2.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.0.0) (4.9.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.0.0) (4.66.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.0.0) (4.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.0.0) (0.26.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.0.0) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.0.0) (3.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.0.0) (1.0.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.0.0) (2023.5.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.0.0) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.0.0) (2.14.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.0.0) (0.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tqdm>4->openai<2.0.0,>=1.0.0) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install \"openai>=1.0.0,<2.0.0\"\n",
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "\n",
    "The Azure OpenAI service supports multiple authentication mechanisms that include API keys and Azure Active Directory token credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_azure_active_directory = False  # Set this flag to True if you are using Azure Active Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication using API key\n",
    "\n",
    "To set up the OpenAI SDK to use an *Azure API Key*, we need to set `api_key` to a key associated with your endpoint (you can find this key in *\"Keys and Endpoints\"* under *\"Resource Management\"* in the [Azure Portal](https://portal.azure.com)). You'll also find the endpoint for your resource here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_azure_active_directory:\n",
    "    endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "    api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "\n",
    "    client = openai.AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "        api_version=\"2023-09-01-preview\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication using Azure Active Directory\n",
    "Let's now see how we can autheticate via Azure Active Directory. We'll start by installing the `azure-identity` library. This library will provide the token credentials we need to authenticate and help us build a token credential provider through the `get_bearer_token_provider` helper function. It's recommended to use `get_bearer_token_provider` over providing a static token to `AzureOpenAI` because this API will automatically cache and refresh tokens for you. \n",
    "\n",
    "For more information on how to set up Azure Active Directory authentication with Azure OpenAI, see the [documentation](https://learn.microsoft.com/azure/ai-services/openai/how-to/managed-identity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-identity>=1.15.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (1.15.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from azure-identity>=1.15.0) (1.27.1)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.24.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from azure-identity>=1.15.0) (1.26.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from azure-identity>=1.15.0) (41.0.1)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from azure-identity>=1.15.0) (1.0.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-identity>=1.15.0) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-identity>=1.15.0) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-identity>=1.15.0) (4.9.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from cryptography>=2.5->azure-identity>=1.15.0) (1.15.1)\n",
      "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from msal<2.0.0,>=1.24.0->azure-identity>=1.15.0) (2.7.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.6 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity>=1.15.0) (2.7.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity>=1.15.0) (2.21)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from portalocker<3,>=1.6->msal-extensions<2.0.0,>=0.3.0->azure-identity>=1.15.0) (305)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-identity>=1.15.0) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-identity>=1.15.0) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-identity>=1.15.0) (2.0.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\johannh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-identity>=1.15.0) (3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install \"azure-identity>=1.15.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "if use_azure_active_directory:\n",
    "    endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "    api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "\n",
    "    client = openai.AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        azure_ad_token_provider=get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"),\n",
    "        api_version=\"2023-09-01-preview\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: the AzureOpenAI infers the following arguments from their corresponding environment variables if they are not provided:\n",
    "\n",
    "- `api_key` from `AZURE_OPENAI_API_KEY`\n",
    "- `azure_ad_token` from `AZURE_OPENAI_AD_TOKEN`\n",
    "- `api_version` from `OPENAI_API_VERSION`\n",
    "- `azure_endpoint` from `AZURE_OPENAI_ENDPOINT`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployments\n",
    "\n",
    "In this section we are going to create a deployment of a GPT model that we can use to call functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployments: Create in the Azure OpenAI Studio\n",
    "Let's deploy a model to use with chat completions. Go to https://portal.azure.com, find your Azure OpenAI resource, and then navigate to the Azure OpenAI Studio. Click on the \"Deployments\" tab and then create a deployment for the model you want to use for chat completions. The deployment name that you give the model will be used in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = \"gpt-4\" # Fill in the deployment name from the portal here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "With setup and authentication complete, you can now use functions with the Azure OpenAI service. This will be split into a few steps:\n",
    "\n",
    "1. Define the function(s)\n",
    "2. Pass function definition(s) into chat completions API\n",
    "3. Call function with arguments from the response\n",
    "4. Feed function response back into chat completions API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define the function(s)\n",
    "\n",
    "A list of functions can be defined, each containing the name of the function, an optional description, and the parameters the function accepts (described as a JSON schema)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_geo_location\",\n",
    "            \"description\": \"Get the geo location of a city as string 'latitude,longitude'. Parameters state and country are optional. Result e.g. '25.245470718844146,51.45400942457904'\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"country\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The country code in format 'ISO 3166-1 alpha-2', e.g. US\",\n",
    "                    },\n",
    "                    \"state\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The state, e.g. CA\",\n",
    "                    },                    \n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city, e.g. San Francisco\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather at a geo location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The geo location as string 'latitude,longitude', e.g. '25.245470718844146,51.45400942457904'\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_n_day_weather_forecast\",\n",
    "            \"description\": \"Get an N-day weather forecast for a geo location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The geo location as string 'latitude,longitude', e.g. '25.245470718844146,51.45400942457904'\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                    \"num_days\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The number of days to forecast\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Declare functions for prompt chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_location(request):\n",
    "    \"\"\"\n",
    "    Get country, state, and city from the user's request.\n",
    "    Create response object with dummy location property for illustrative purposes.\n",
    "    \"\"\"\n",
    "    country = request.get(\"country\")\n",
    "    state = request.get(\"state\")\n",
    "    city = request.get(\"city\")\n",
    "    return {\"location\": \"25.245470718844146,51.45400942457904\"}\n",
    "\n",
    "def get_current_weather(request):\n",
    "    \"\"\"\n",
    "    This function is for illustrative purposes.\n",
    "    The location and unit should be used to determine weather\n",
    "    instead of returning a hardcoded response.\n",
    "    \"\"\"\n",
    "    location = request.get(\"location\")\n",
    "    format = request.get(\"format\")\n",
    "    return {\"temperature\": \"22\", \"format\": \"celsius\", \"description\": \"Sunny\"}\n",
    "\n",
    "def get_n_day_weather_forecast(request):\n",
    "    \"\"\"\n",
    "    This function is for illustrative purposes.\n",
    "    The location and unit should be used to determine weather\n",
    "    instead of returning a hardcoded response.\n",
    "    \"\"\"\n",
    "    location = request.get(\"location\")\n",
    "    format = request.get(\"format\")\n",
    "    num_days = request.get(\"num_days\")\n",
    "    return {\"temperature\": \"30\", \"format\": \"farenheit\", \"description\": \"Sunny\", \"num_days\": num_days}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Pass function definition(s) into chat completions API\n",
    "\n",
    "Now we can pass the function into the chat completions API. If the model determines it should call the function, a `finish_reason` of \"tool_calls\" will be populated on the choice and the details of which function to call and its arguments will be present in the `message`. Optionally, you can set the `tool_choice` keyword argument to force the model to call a particular function (e.g. `{\"type\": \"function\", \"function\": {\"name\": get_current_weather}}`). By default, this is set to `auto`, allowing the model to choose whether to call the function or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Initial messages: \n",
      "[{\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"}, {\"role\": \"user\", \"content\": \"What's the weather like? In 20 days in London? Today in Seattle, WA, CA?\"}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Initial response: \n",
      "ChatCompletion(id='chatcmpl-8n26odTb14SpbbBnzMVSIT4YX2Acz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='To clarify, do you want to know the weather for Seattle in the state of Washington or the city in California?', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1706696870, model='gpt-4', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=24, prompt_tokens=356, total_tokens=380), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"},\n",
    "\n",
    "# Exact function declaration is important to detect the functions and optional parameters, not ending in infinitive loop calling the same function!\n",
    "\n",
    "# User messages to test the bot. Country and state are optional.\n",
    "\n",
    "# Chaining single ok, first get_geo_location, then get_current_weather\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like today in Seattle, WA, US?\"}\n",
    "\n",
    "# Chaining single ok, first get_geo_location, then get_n_day_weather_forecast\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like in 20 days in Seattle, WA, US?\"}\n",
    "\n",
    "# Chaining single ok, first get_geo_location, then get_current_weather\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like today in Seattle?\"}\n",
    "\n",
    "# Chaining multiple ok first get_geo_location, then get_current_weather\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like today in the following cities: Seattle and New York?\"}\n",
    "\n",
    "# Chaining single ok, first get_geo_location, then get_n_day_weather_forecast\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like in 20 days in Seattle?\"}\n",
    "\n",
    "# Chaining multiple ok, first get_geo_location, then get_n_day_weather_forecast\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like? In 20 days in Seattle and in 30 days in New York?\"}\n",
    "\n",
    "# Chaining multiple mixed ok, first get_geo_location, then get_current_weather / get_n_day_weather_forecast\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like? Today in Seattle and in 30 days in New York?\"}\n",
    "\n",
    "# Direct call single ok: get_current_weather\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like today at 25.245470718844146,51.45400942457904?\"},\n",
    "\n",
    "# Direct call multiple ok: get_current_weather\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like today at 25.245470718844146,51.45400942457904 and at 52.245470718844146,15.45400942457904?\"},\n",
    "\n",
    "# Direct call single ok: get_n_day_weather_forecast\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like in 15 days at 25.245470718844146,51.45400942457904?\"}\n",
    "\n",
    "# Direct call multiple ok: get_n_day_weather_forecast\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like? In 15 days at 25.245470718844146,51.45400942457904? In 30 days at 52.245470718844146,15.45400942457904?\"}\n",
    "\n",
    "# Direct call multiple mixed ok: get_geo_location, get_current_weather, get_n_day_weather_forecast\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like? Today in New York? Tomorrow in London? In 15 days at 25.245470718844146,51.45400942457904? In 30 days at 52.245470718844146,15.45400942457904?\"}\n",
    "\n",
    "# result: single confusion: Seattle is in WA, US\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like in 20 days in Seattle, WA, CA?\"}\n",
    "\n",
    "# result: mixed confusion: Seattle is in WA, US - but London is ok - still all confused and no function call\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like in 20 days in London and Seattle, WA, CA?\"}\n",
    "\n",
    "# result: mixed confusion: Seattle is in WA, US - but London is ok - still all confused and no function call\n",
    "#    {\"role\": \"user\", \"content\": \"What's the weather like? In 20 days in London? Today in Seattle, WA, CA?\"}\n",
    "]\n",
    "\n",
    "print (\"- Initial messages: \")\n",
    "print (json.dumps(messages))\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "print (\"- Initial response: \")\n",
    "print(chat_completion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Call function with arguments from the response and feed function response back into chat completions API\n",
    "\n",
    "The name of the function call will be one that was provided initially and the arguments will include JSON matching the schema included in the function definition.\n",
    "\n",
    "The response from the function should be serialized into a new message with the role set to \"function\". Now the model will use the response data to formulate its answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Final message ##########################################\n",
      "To clarify, do you want to know the weather for Seattle in the state of Washington or the city in California?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "auto_interaction_max = 10\n",
    "auto_interaction_counter = 0\n",
    "\n",
    "# loop until either chat_completion has no choices or the first choice is no function\n",
    "while auto_interaction_counter < auto_interaction_max and len(chat_completion.choices) > 0 and chat_completion.choices[0].message.tool_calls:\n",
    "    auto_interaction_counter += 1\n",
    "\n",
    "    print (\"\\n### Processing {}. automatic interaction ##########################################\".format(auto_interaction_counter))\n",
    "\n",
    "    # extend conversation with assistant's reply to avoid error code 400: Invalid parameter: messages with role 'tool' must be a response to a preceeding message with 'tool_calls'.\n",
    "    messages.append(chat_completion.choices[0].message)  \n",
    "\n",
    "    # Process all function calls \n",
    "    for tool_call in chat_completion.choices[0].message.tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_arguments = tool_call.function.arguments\n",
    "        print(\"\\n### Call function: {} [ID: {}]: {}\".format(function_name, tool_call.id, function_arguments.replace('\\n', ' ').replace('\\r', '')))\n",
    "\n",
    "        # Process function call\n",
    "        unknown_tool = False\n",
    "        if function_name == \"get_current_weather\":\n",
    "            tool_result = get_current_weather(json.loads(function_arguments))\n",
    "        elif function_name == \"get_n_day_weather_forecast\":\n",
    "            tool_result = get_n_day_weather_forecast(json.loads(function_arguments))\n",
    "        elif function_name == \"get_geo_location\":\n",
    "            tool_result = get_geo_location(json.loads(function_arguments))\n",
    "        else:\n",
    "            tool_result = \"\"\n",
    "            unknown_tool = True\n",
    "\n",
    "        # Print function result            \n",
    "        if unknown_tool:\n",
    "            print(\"- Unknown Function: {}\".format(function_name))\n",
    "        else:\n",
    "            print(\"- Function Result: {}\".format(tool_result))\n",
    "\n",
    "            # Append tool call id to result\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": json.dumps(tool_result)\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # List overall updated message and do reprocessing\n",
    "    print (\"- Updated messages: {}\".format(messages))\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "# Final chat result without function calls\n",
    "print (\"\\n### Final message ##########################################\")\n",
    "if chat_completion.choices[0].message.content:\n",
    "    print(chat_completion.choices[0].message.content.strip())\n",
    "else:\n",
    "    print(chat_completion.choices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a5103089ab7e7c666b279eeded403fcec76de49a40685dbdfe9f9c78ad97c17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
